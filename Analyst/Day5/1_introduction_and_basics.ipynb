{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e104077d",
   "metadata": {},
   "source": [
    "# clEsperanto: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0136a9",
   "metadata": {},
   "source": [
    "The python package `pyclesperanto` can be install using `pip` or `mamba`. If all went well, there shouldn't be any issue at the package import stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2669c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyclesperanto as cle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46722a3",
   "metadata": {},
   "source": [
    "`clEsperanto` runs on __OpenCL__ (Open Computing Language) which is a standard language for parallel programming of diverse Processing Units which can be Graphical (GPU) or Central (CPU). Strong point of the language is its compatibility with a vast set of devices. At import, clesperanto will automatically select a device (the first one found) but it might not be the best nor the one you want to select is you have more than one device.\n",
    "\n",
    "Hence, the first step is to prospect your hardware and identify the best device to run our operations. We provide the following function to enquiry and manage the Processing Units of your system.\n",
    "\n",
    "### Exercice 1: System specification\n",
    "\n",
    "Using `cle.info()` fetch your full system specification: How many devices available do you have? Which device is the most adapted for you?\n",
    "\n",
    "Here are a few quick definition:\n",
    "\n",
    "- __GLOBAL_MEM_SIZE__: Total RAM memory of the device\n",
    "- __MAX_MEM_ALLOC_SIZE__: Maximum RAM memory allocation possible\n",
    "- __MAX_COMPUTE_UNITS__: Number of computing core of the Processing Unit\n",
    "- __MAX_CLOCK_FREQUENCY__: Processing speed of each core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1c72e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Check your system information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08069768",
   "metadata": {},
   "source": [
    "### Exercice 2: Select a device\n",
    "\n",
    "Using `cle.select_device()`, select a specific device from your system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "84d1576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - select a specific device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832ec4e7",
   "metadata": {},
   "source": [
    "The devices memory and main computer memory are separated, in order for a device to acces a data it requires to transfert it from the main memory to the device memory, and to transfert it back to the main computer memory once all processing are done. \n",
    "\n",
    "Because of this, `clesperanto` comes with its own array structure which is compatible with `numpy.array`, and a set of function to send and read from the device:\n",
    "- `push()` : send an array from CPU to GPU\n",
    "- `pull()` : read an array from GPU to CPU\n",
    "- `create()` : allocate empty space on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a88e32a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_arr:  shape=(5, 10), dtype=float64, device=cpu, type=<class 'numpy.ndarray'>\n",
      "gpu_arr: shape=(5, 10), dtype=float32, device=NVIDIA GeForce RTX 4090, type=<class 'pyclesperanto._pyclesperanto._Array'>\n",
      "out_arr: shape=(5, 10), dtype=float32, device=cpu, type=<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "np_arr = np.random.rand(5,10)  # CPU array\n",
    "gpu_arr = cle.push(np_arr)    # GPU array\n",
    "out_arr = cle.pull(gpu_arr)   # CPU array\n",
    "\n",
    "print(f\"np_arr:  shape={np_arr.shape}, dtype={np_arr.dtype}, device={np_arr.device}, type={type(np_arr)}\")\n",
    "print(f\"gpu_arr: shape={gpu_arr.shape}, dtype={gpu_arr.dtype}, device={gpu_arr.device.name}, type={type(gpu_arr)}\")\n",
    "print(f\"out_arr: shape={out_arr.shape}, dtype={out_arr.dtype}, device={out_arr.device}, type={type(out_arr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0a672192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5488135  0.71518934 0.60276335 0.5448832  0.4236548  0.6458941\n",
      "  0.4375872  0.891773   0.96366274 0.3834415 ]\n",
      " [0.79172504 0.5288949  0.56804454 0.92559665 0.07103606 0.0871293\n",
      "  0.0202184  0.83261985 0.77815676 0.87001216]\n",
      " [0.9786183  0.7991586  0.46147937 0.7805292  0.11827443 0.639921\n",
      "  0.14335328 0.9446689  0.5218483  0.41466194]\n",
      " [0.2645556  0.7742337  0.45615032 0.56843394 0.0187898  0.6176355\n",
      "  0.6120957  0.616934   0.94374806 0.6818203 ]\n",
      " [0.3595079  0.43703195 0.6976312  0.06022547 0.6667667  0.67063785\n",
      "  0.21038257 0.12892629 0.31542835 0.36371076]]\n",
      "\n",
      "gpu arr(0,0)= [[0.5488135]]\n"
     ]
    }
   ],
   "source": [
    "print(gpu_arr)\n",
    "print(\"\\ngpu arr(0,0)=\", gpu_arr[0,0])  # Accessing element at (0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89315076",
   "metadata": {},
   "source": [
    "### Exercice 1: Load an image into your device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8f98fd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "image = imread(\"https://imagej.net/ij/images/3_channel_inverted_luts.tif\")\n",
    "\n",
    "# TODO - check the image shape and push it to the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd13eb27",
   "metadata": {},
   "source": [
    "### Exercise 2: What is the largest array you can push to your device?\n",
    "\n",
    "One of the biggest limitation in GPU-acceleration is the memory limitation of your device, what is the size data you can push to your device? Does it fit your hardware specification?  \n",
    "Here, we want to see your hardware limitation and the type of error you would get if this happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "92106951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - generate a large numpy array and push it to the GPU until ... it crashes ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a806bda",
   "metadata": {},
   "source": [
    "You can trace your device usage with various OSs application to see memory occupancy and the core usage:\n",
    "- MacOS: Activity Monitor > View > GPU History\n",
    "- Windows: Task Manager > Performance\n",
    "- NVIDIA: run `watch -n0.1 nvidia-smi` in a prompt / terminal\n",
    "- ...\n",
    "\n",
    "Now that you manage to fill up your device memory, delete the variable using `del`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9a7c2c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - delete the GPU variable array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea532575",
   "metadata": {},
   "source": [
    "# Cupy: Introduction\n",
    "\n",
    "> [WARNING]\n",
    "> Only for NVIDIA Hardware !\n",
    "\n",
    "Cupy is a library for processing data using __CUDA__ (Compute Unified Device Architecture) a proprietary language for NVIDIA graphics cards __only__.\n",
    "\n",
    "It is a numpy/scipy compatible library for GPU acceleration and can act as a dropin replacement, with a seemless integration to the __numpy__ ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf008ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'cupy' from '/home/strigaud/Libraries/miniforge3/envs/skbe/lib/python3.12/site-packages/cupy/__init__.py'>\n",
      "<module 'cupyx.scipy.ndimage' from '/home/strigaud/Libraries/miniforge3/envs/skbe/lib/python3.12/site-packages/cupyx/scipy/ndimage/__init__.py'>\n",
      "\n",
      "<module 'numpy' from '/home/strigaud/Libraries/miniforge3/envs/skbe/lib/python3.12/site-packages/numpy/__init__.py'>\n",
      "<module 'scipy.ndimage' from '/home/strigaud/Libraries/miniforge3/envs/skbe/lib/python3.12/site-packages/scipy/ndimage/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import cupy as xp\n",
    "except:\n",
    "    import numpy as xp\n",
    "    Warning(\"Cupy not found, using numpy instead.\")\n",
    "\n",
    "try:\n",
    "    import cupyx.scipy.ndimage as xdi\n",
    "except:\n",
    "    import scipy.ndimage as xdi\n",
    "    Warning(\"Cupy not found, using scipy instead.\")\n",
    "\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "print(xp)\n",
    "print(xdi)\n",
    "print()\n",
    "print(np)\n",
    "print(ndi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c108a83",
   "metadata": {},
   "source": [
    "Because it is CUDA based, only NVIDIA device can be used. Hence, you can identify the hardware you want to use based on their __index__ which is based on the library discovery pattern which can change vary between system and version.\n",
    "\n",
    "We can explore the devices specificities and we should recover similar information than with `clesperanto` with possible different name convention or units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1b0ce526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0:\n",
      "- name: b'NVIDIA GeForce RTX 4090'\n",
      "- totalGlobalMem: 25358630912\n",
      "- sharedMemPerBlock: 49152\n",
      "- regsPerBlock: 65536\n",
      "- warpSize: 32\n",
      "- maxThreadsPerBlock: 1024\n",
      "- maxThreadsDim: (1024, 1024, 64)\n",
      "- maxGridSize: (2147483647, 65535, 65535)\n",
      "- clockRate: 2520000\n",
      "- totalConstMem: 65536\n",
      "- major: 8\n",
      "- minor: 9\n",
      "- textureAlignment: 512\n",
      "- texturePitchAlignment: 32\n",
      "- multiProcessorCount: 128\n",
      "- kernelExecTimeoutEnabled: 1\n",
      "- integrated: 0\n",
      "- canMapHostMemory: 1\n",
      "- computeMode: 0\n",
      "- maxTexture1D: 131072\n",
      "- maxTexture2D: (131072, 65536)\n",
      "- maxTexture3D: (16384, 16384, 16384)\n",
      "- concurrentKernels: 1\n",
      "- ECCEnabled: 0\n",
      "- pciBusID: 1\n",
      "- pciDeviceID: 0\n",
      "- pciDomainID: 0\n",
      "- tccDriver: 0\n",
      "- memoryClockRate: 10501000\n",
      "- memoryBusWidth: 384\n",
      "- l2CacheSize: 75497472\n",
      "- maxThreadsPerMultiProcessor: 1536\n",
      "- isMultiGpuBoard: 0\n",
      "- cooperativeLaunch: 1\n",
      "- cooperativeMultiDeviceLaunch: 1\n",
      "- deviceOverlap: 1\n",
      "- maxTexture1DMipmap: 32768\n",
      "- maxTexture1DLinear: 268435456\n",
      "- maxTexture1DLayered: (32768, 2048)\n",
      "- maxTexture2DMipmap: (32768, 32768)\n",
      "- maxTexture2DLinear: (131072, 65000, 2097120)\n",
      "- maxTexture2DLayered: (32768, 32768, 2048)\n",
      "- maxTexture2DGather: (32768, 32768)\n",
      "- maxTexture3DAlt: (8192, 8192, 32768)\n",
      "- maxTextureCubemap: 32768\n",
      "- maxTextureCubemapLayered: (32768, 2046)\n",
      "- maxSurface1D: 32768\n",
      "- maxSurface1DLayered: (32768, 2048)\n",
      "- maxSurface2D: (131072, 65536)\n",
      "- maxSurface2DLayered: (32768, 32768, 2048)\n",
      "- maxSurface3D: (16384, 16384, 16384)\n",
      "- maxSurfaceCubemap: 32768\n",
      "- maxSurfaceCubemapLayered: (32768, 2046)\n",
      "- surfaceAlignment: 512\n",
      "- asyncEngineCount: 2\n",
      "- unifiedAddressing: 1\n",
      "- streamPrioritiesSupported: 1\n",
      "- globalL1CacheSupported: 1\n",
      "- localL1CacheSupported: 1\n",
      "- sharedMemPerMultiprocessor: 102400\n",
      "- regsPerMultiprocessor: 65536\n",
      "- managedMemory: 1\n",
      "- multiGpuBoardGroupID: 0\n",
      "- hostNativeAtomicSupported: 0\n",
      "- singleToDoublePrecisionPerfRatio: 64\n",
      "- pageableMemoryAccess: 0\n",
      "- concurrentManagedAccess: 1\n",
      "- computePreemptionSupported: 1\n",
      "- canUseHostPointerForRegisteredMem: 1\n",
      "- sharedMemPerBlockOptin: 101376\n",
      "- pageableMemoryAccessUsesHostPageTables: 0\n",
      "- directManagedMemAccessFromHost: 0\n",
      "- uuid: b'G\\xb2\\xd4lt\\xa8\\x15\\xd9\\xe5\\xbe\\xa1\\x91\\xa1\\x9b\\x9a\\xc3'\n",
      "- luid: b''\n",
      "- luidDeviceNodeMask: 0\n",
      "- persistingL2CacheMaxSize: 51904512\n",
      "- maxBlocksPerMultiProcessor: 24\n",
      "- accessPolicyMaxWindowSize: 134213632\n",
      "- reservedSharedMemPerBlock: 1024\n",
      "Device 1:\n",
      "- name: b'NVIDIA GeForce RTX 4090'\n",
      "- totalGlobalMem: 25393692672\n",
      "- sharedMemPerBlock: 49152\n",
      "- regsPerBlock: 65536\n",
      "- warpSize: 32\n",
      "- maxThreadsPerBlock: 1024\n",
      "- maxThreadsDim: (1024, 1024, 64)\n",
      "- maxGridSize: (2147483647, 65535, 65535)\n",
      "- clockRate: 2625000\n",
      "- totalConstMem: 65536\n",
      "- major: 8\n",
      "- minor: 9\n",
      "- textureAlignment: 512\n",
      "- texturePitchAlignment: 32\n",
      "- multiProcessorCount: 128\n",
      "- kernelExecTimeoutEnabled: 1\n",
      "- integrated: 0\n",
      "- canMapHostMemory: 1\n",
      "- computeMode: 0\n",
      "- maxTexture1D: 131072\n",
      "- maxTexture2D: (131072, 65536)\n",
      "- maxTexture3D: (16384, 16384, 16384)\n",
      "- concurrentKernels: 1\n",
      "- ECCEnabled: 0\n",
      "- pciBusID: 3\n",
      "- pciDeviceID: 0\n",
      "- pciDomainID: 0\n",
      "- tccDriver: 0\n",
      "- memoryClockRate: 10501000\n",
      "- memoryBusWidth: 384\n",
      "- l2CacheSize: 75497472\n",
      "- maxThreadsPerMultiProcessor: 1536\n",
      "- isMultiGpuBoard: 0\n",
      "- cooperativeLaunch: 1\n",
      "- cooperativeMultiDeviceLaunch: 1\n",
      "- deviceOverlap: 1\n",
      "- maxTexture1DMipmap: 32768\n",
      "- maxTexture1DLinear: 268435456\n",
      "- maxTexture1DLayered: (32768, 2048)\n",
      "- maxTexture2DMipmap: (32768, 32768)\n",
      "- maxTexture2DLinear: (131072, 65000, 2097120)\n",
      "- maxTexture2DLayered: (32768, 32768, 2048)\n",
      "- maxTexture2DGather: (32768, 32768)\n",
      "- maxTexture3DAlt: (8192, 8192, 32768)\n",
      "- maxTextureCubemap: 32768\n",
      "- maxTextureCubemapLayered: (32768, 2046)\n",
      "- maxSurface1D: 32768\n",
      "- maxSurface1DLayered: (32768, 2048)\n",
      "- maxSurface2D: (131072, 65536)\n",
      "- maxSurface2DLayered: (32768, 32768, 2048)\n",
      "- maxSurface3D: (16384, 16384, 16384)\n",
      "- maxSurfaceCubemap: 32768\n",
      "- maxSurfaceCubemapLayered: (32768, 2046)\n",
      "- surfaceAlignment: 512\n",
      "- asyncEngineCount: 2\n",
      "- unifiedAddressing: 1\n",
      "- streamPrioritiesSupported: 1\n",
      "- globalL1CacheSupported: 1\n",
      "- localL1CacheSupported: 1\n",
      "- sharedMemPerMultiprocessor: 102400\n",
      "- regsPerMultiprocessor: 65536\n",
      "- managedMemory: 1\n",
      "- multiGpuBoardGroupID: 1\n",
      "- hostNativeAtomicSupported: 0\n",
      "- singleToDoublePrecisionPerfRatio: 64\n",
      "- pageableMemoryAccess: 0\n",
      "- concurrentManagedAccess: 1\n",
      "- computePreemptionSupported: 1\n",
      "- canUseHostPointerForRegisteredMem: 1\n",
      "- sharedMemPerBlockOptin: 101376\n",
      "- pageableMemoryAccessUsesHostPageTables: 0\n",
      "- directManagedMemAccessFromHost: 0\n",
      "- uuid: b'W\\x95\\xbbW\\x7f\\x7f\\xae\\xd9\\xe4\\xf0,<\\xb4\\xd7\\x14\\xcf'\n",
      "- luid: b''\n",
      "- luidDeviceNodeMask: 0\n",
      "- persistingL2CacheMaxSize: 51904512\n",
      "- maxBlocksPerMultiProcessor: 24\n",
      "- accessPolicyMaxWindowSize: 134213632\n",
      "- reservedSharedMemPerBlock: 1024\n"
     ]
    }
   ],
   "source": [
    "num_devices = xp.cuda.runtime.getDeviceCount()\n",
    "for i in range(num_devices):\n",
    "    print(f\"Device {i}:\")\n",
    "    device_properties = xp.cuda.runtime.getDeviceProperties(i)\n",
    "    for k, v in device_properties.items():\n",
    "        print(f\"- {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0798ff5b",
   "metadata": {},
   "source": [
    "Even if the interface allows dropin-replacement, the memory still requires a copy from the CPU memory to the GPU memory. Here, Cupy rely on a numpy style api with `asarray` and `get` methods to transfert the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "50bfae8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_arr:  shape=(5, 10), dtype=float64, device=cpu, type=<class 'numpy.ndarray'>\n",
      "gpu_arr: shape=(5, 10), dtype=float64, device=<CUDA Device 0>, type=<class 'cupy.ndarray'>\n",
      "out_arr: shape=(5, 10), dtype=float64, device=cpu, type=<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "np_arr = np.random.rand(5,10)  # CPU array\n",
    "gpu_arr = xp.asarray(np_arr)   # GPU array\n",
    "out_arr = gpu_arr.get()        # CPU array\n",
    "\n",
    "print(f\"np_arr:  shape={np_arr.shape}, dtype={np_arr.dtype}, device={np_arr.device}, type={type(np_arr)}\")\n",
    "print(f\"gpu_arr: shape={gpu_arr.shape}, dtype={gpu_arr.dtype}, device={gpu_arr.device}, type={type(gpu_arr)}\")\n",
    "print(f\"out_arr: shape={out_arr.shape}, dtype={out_arr.dtype}, device={out_arr.device}, type={type(out_arr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c2ae59d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5488135  0.71518937 0.60276338 0.54488318 0.4236548  0.64589411\n",
      "  0.43758721 0.891773   0.96366276 0.38344152]\n",
      " [0.79172504 0.52889492 0.56804456 0.92559664 0.07103606 0.0871293\n",
      "  0.0202184  0.83261985 0.77815675 0.87001215]\n",
      " [0.97861834 0.79915856 0.46147936 0.78052918 0.11827443 0.63992102\n",
      "  0.14335329 0.94466892 0.52184832 0.41466194]\n",
      " [0.26455561 0.77423369 0.45615033 0.56843395 0.0187898  0.6176355\n",
      "  0.61209572 0.616934   0.94374808 0.6818203 ]\n",
      " [0.3595079  0.43703195 0.6976312  0.06022547 0.66676672 0.67063787\n",
      "  0.21038256 0.1289263  0.31542835 0.36371077]]\n",
      "\n",
      "gpu arr(0,0)= 0.5488135039273248\n"
     ]
    }
   ],
   "source": [
    "print(gpu_arr)\n",
    "print(\"\\ngpu arr(0,0)=\", gpu_arr[0,0])  # Accessing element at (0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d4366b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skbe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
