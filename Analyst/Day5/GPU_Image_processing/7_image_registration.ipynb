{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98ae1a12-cecc-497c-a88a-0a3c8ee18359",
   "metadata": {},
   "source": [
    "# Group Challenge 2: Image Registration\n",
    "\n",
    "Let's try to register two images using clesperanto library\n",
    "\n",
    "This notebook is unrelated to the [challenge 2 notebook](https://github.com/Image-Analysis-Hub/Pasteur-BioImage-Analysis-Course-2025/blob/main/Analyst/Day1/napari-plugin/GroupChallenges/Challenge_2_Image_Registration.ipynb) on napari widget by Daniel Krentzel, __all similitude are purely coincidental!__\n",
    "\n",
    "## Register images\n",
    "\n",
    "clesperanto currently only provide a `local_cross_correlation` algorithm to measure the similitude between two image and find possible transformation between two images. More algorithm for image registration to come soon\n",
    "\n",
    "## Transform Matrix\n",
    "\n",
    "<div>\n",
    "    <center><img src=https://github.com/Image-Analysis-Hub/Pasteur-BioImage-Analysis-Course-2025/blob/main/Analyst/Day1/napari-plugin/GroupChallenges/Images/affine_transformation_matrix.png?raw=true width=300/><center>\n",
    "</div>\n",
    "\n",
    "## Transform an image\n",
    "\n",
    "We applied a transformation to a data, let's try to find back the translation operation using the `local_cross_correlation` and apply the transformation to register the two images using some transform operations (e.g. translate or affine transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c37a6-acd2-435f-90f5-2cf0b68e2eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import pyclesperanto as cle\n",
    "\n",
    "IMAGE2D = data.cells3d()[30,1]\n",
    "\n",
    "trafo_matrix = np.eye(3)\n",
    "trafo_matrix[0,2] = -22.4\n",
    "trafo_matrix[1,2] = 13.2  \n",
    "trafo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44caaa5a-3b2d-4a5e-9736-c5b9d273c304",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_mat = np.linalg.inv(trafo_matrix)\n",
    "IMAGE2D_offset = ndimage.affine_transform(input=IMAGE2D,\n",
    "                                          matrix=inv_mat,\n",
    "                                          output_shape=IMAGE2D.shape,\n",
    "                                          order=2)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10,20))\n",
    "ax[0].imshow(IMAGE2D, cmap='gray')\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('Fixed image')\n",
    "ax[1].imshow(IMAGE2D_offset, cmap='gray')\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('Moving image')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61cb080-ba7f-4006-9489-b3b2ea991422",
   "metadata": {},
   "source": [
    "## Exercise 1: find back the translation matrix and apply its reverse to the `offset` image\n",
    "\n",
    "You can rely on the `local_cross_correlation` to find back the translation and the `tranlate` or `affine_transform` operation to correct the shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c18713-a81a-42f2-84b2-1df799f0eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use local_cross_correlation and translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fcef91-3347-4a5f-bc8b-0958d1c1b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use an affine_transform"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
