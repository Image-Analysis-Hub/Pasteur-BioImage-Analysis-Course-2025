{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6390dd3c-7301-4167-b35c-eb2cd375f5b8",
   "metadata": {},
   "source": [
    "# Large data processing\n",
    "\n",
    "The biggest limitation to GPU-processing, beside its learning curve, is the memory space. It does not go higher than `32Gb` for commercial GPU. This can easily limits the maximum image size to process to `8Gb`, even less when we want to apply more complex algorithm requiring temporary steps.\n",
    "\n",
    "This issue already exist outside of GPU-acceleartion and the solution is to tile our image and process each tile separatly to overcome the memory bottleneck. We can rely on the `dask` library to distribute our data accross our list of device, in the same way we would do on an HPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa8694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import dask.distributed as dd\n",
    "\n",
    "import timeit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyclesperanto as cle\n",
    "try:\n",
    "    import cupy as xp\n",
    "except:\n",
    "    import numpy as xp\n",
    "    Warning(\"Cupy not found, using numpy instead.\")\n",
    "try:\n",
    "    import cupyx.scipy.ndimage as xdi\n",
    "except:\n",
    "    import scipy.ndimage as xdi\n",
    "    Warning(\"Cupy not found, using scipy instead.\")\n",
    "\n",
    "import zarr\n",
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dceec6",
   "metadata": {},
   "source": [
    "## Define dask client\n",
    "\n",
    "For GPU usage, we will want to have one dask worker per device to use. We can have more than one thread per worker but, depending on the memory usage of the pipeline to run this can jam the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4656981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_devices = len(cle.list_available_devices(device_type=\"gpu\"))\n",
    "\n",
    "cluster = dd.LocalCluster(n_workers=nb_devices, threads_per_worker=1, processes=False)\n",
    "client = dd.Client(cluster)\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3414ad06",
   "metadata": {},
   "source": [
    "We can associate each worker of our client to the index of a device of clesperanto using a `dict`. This will allows use to switch devices based on the worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e0934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = client.scheduler_info()['workers']\n",
    "worker_dev_map = {worker: idx for idx, worker in enumerate(workers)}\n",
    "for worker in workers:\n",
    "    print(worker_dev_map[worker], \"-\", worker, \":\" ,cle.select_device(worker_dev_map[worker], device_type=\"gpu\").name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f775d2",
   "metadata": {},
   "source": [
    "## Load zarr data\n",
    "\n",
    "We use a dataset that is provided by Theresa Suckert, OncoRay, University Hospital Carl Gustav Carus, TU Dresden. The dataset is licensed License: CC-BY 4.0. We are using a cropped version here that was resaved a 8-bit image to be able to provide it with the notebook. You find the full size 16-bit image in CZI file format online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efa7fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "darray = da.from_zarr(\"./data/P1_H_C3H_M004_17-cropped.zarr\", chunks=(2, 1000, 1000))  # Adjust the chunk size as needed\n",
    "darray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb8e2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(30, 10))\n",
    "axs[0].imshow(darray[0], cmap='gray')\n",
    "axs[1].imshow(darray[1], cmap='gray')\n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63ea129",
   "metadata": {},
   "source": [
    "### clesperanto mini-Pipeline\n",
    "\n",
    "Now we can build a small pipeline that will be run for each block of the dask and compute the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60edf446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cle_operation(image, block_info=None):\n",
    "    # fetch the device associate to the worker\n",
    "    worker = dd.get_worker()\n",
    "    gpu_index = worker_dev_map[worker.address]\n",
    "    device = cle.select_device(gpu_index, \"gpu\")\n",
    "    chunk_coord = block_info[None]['chunk-location'] if block_info is not None else None\n",
    "\n",
    "    print(f\"Processing chunk {chunk_coord} with {device.name} ({gpu_index})\")\n",
    "\n",
    "    # TODO: add processing here\n",
    "\n",
    "    # return the results as numpy array\n",
    "    return np.asarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94eeab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_image = da.map_overlap(cle_operation, darray, dtype=darray.dtype)\n",
    "processed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350625b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "result = processed_image.compute()\n",
    "end = timeit.default_timer()\n",
    "print(f\"Time to compute: {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be316538",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(30, 10))\n",
    "axs[0].imshow(result[0], cmap='viridis')\n",
    "axs[1].imshow(result[1], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd72881",
   "metadata": {},
   "source": [
    "## Exercise 1: Apply some processing on the image\n",
    "\n",
    "Process the image to segment the nuclei and count them per image block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c0f397",
   "metadata": {},
   "source": [
    "## Additionnal Use-Case: Data projection & overlap\n",
    "\n",
    "An other example for large data processing, in the case of data projection. Here we have a large 3D tissue from a slide scanner (~30Gb) that need to be projected before thurther analysis. Here we will focus on a crop \n",
    "\n",
    "This use-case was done by Emily Haimerl ([Gaia Novarino Lab](https://ist.ac.at/en/research/novarino-group/)), Maximilian Schuster, and Marco Dalla Vecchia ([Imaging & Optics Facility](https://iof.pages.ist.ac.at/)) from ISTA (Vienna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de18f91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "darray = da.from_zarr(\"./data/WT_ScanRegion4-cropped.zarr\", chunks=(28, 2, 2000, 2000))  # Adjust the chunk size as needed\n",
    "darray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01541944",
   "metadata": {},
   "source": [
    "The objectives is to project the volume with the optic to keep the nuclei in focus. For that we use maximum local variance projection to identify the best focus plan and a top hat filter to remove the background. The objectives beeing to segment the nuclei and count the number of nuclei positive in the tissue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90620903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cle_operation(image, block_info=None):\n",
    "    # fetch the device associate to the worker\n",
    "    worker = dd.get_worker()\n",
    "    gpu_index = worker_dev_map[worker.address]\n",
    "    device = cle.select_device(gpu_index, \"gpu\")\n",
    "    chunk_coord = block_info[None]['chunk-location'] if block_info is not None else None\n",
    "\n",
    "    # pre-processing for projecting best focus intensity in each pixel\n",
    "    img_dev = cle.push(image, device=device)\n",
    "    proj = cle.extended_depth_of_focus_variance_projection(img_dev, sigma=100)\n",
    "    bged = cle.top_hat(proj, radius_x=30.0, radius_y=30.0, connectivity=\"box\")\n",
    "\n",
    "    # return the results as numpy array\n",
    "    return np.asarray(bged)\n",
    "\n",
    "processed_image = da.map_overlap(cle_operation, darray[:,0,...], dtype=darray.dtype, drop_axis=[0], depth=[0, 40, 40])\n",
    "processed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4660ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "result = processed_image.compute()\n",
    "end = timeit.default_timer()\n",
    "print(f\"Time to compute: {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94faab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(30, 10))\n",
    "axs[0].imshow(result, cmap='viridis')\n",
    "# draw a box around the region of interest\n",
    "axs[0].add_patch(plt.Rectangle((5000, 5000), 1000, 1000, edgecolor='red', facecolor='none', lw=2))\n",
    "axs[1].imshow(result[5000:6000, 5000:6000], cmap='viridis')\n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3d225a-97ce-4806-8154-5802dcd50424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
