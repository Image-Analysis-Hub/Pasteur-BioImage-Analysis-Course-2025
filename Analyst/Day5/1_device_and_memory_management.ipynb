{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e104077d",
   "metadata": {},
   "source": [
    "# Devices and Memory management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc03f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyclesperanto as cle\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from skimage.io import imread, imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46722a3",
   "metadata": {},
   "source": [
    "## Devices\n",
    "\n",
    "`clEsperanto` runs on __OpenCL__ (Open Computing Language) which is a standard language for parallel programming of diverse Processing Units which can be Graphical (GPU) or Central (CPU).\n",
    "The first step is to propect our hardware and identify the best device to run our operations. We provide the following function to enquiry and manage the Processing Units of your system:\n",
    "- `cle.info()` \n",
    "- `cle.list_available_devices()` \n",
    "- `cle.select_device()`\n",
    "- `cle.get_device()`\n",
    "\n",
    "### Exercice 1: System specification\n",
    "\n",
    "Using `cle.info()` fetch your system specification, How many devices available do you have? Which device is the most adapted for you?\n",
    "\n",
    "Here are a few definition:\n",
    "\n",
    "- __GLOBAL_MEM_SIZE__: Total RAM memory of the device\n",
    "- __MAX_MEM_ALLOC_SIZE__: Maximum RAM memory allocation possible\n",
    "- __MAX_COMPUTE_UNITS__: Number of computing core of the Processing Unit\n",
    "- __MAX_CLOCK_FREQUENCY__: Processing speed of each core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c72e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Check your system information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08069768",
   "metadata": {},
   "source": [
    "### Exercice 2: Select a device\n",
    "\n",
    "Select a specific device and store in a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d1576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - select a specific device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832ec4e7",
   "metadata": {},
   "source": [
    "## Memory management\n",
    "\n",
    "The devices memory and main computer memory are separated, in order for a device to acces a data it requires to transfert it from the main memory to the device memory, and to transfert it back to the main computer memory once all processing are done. For this, we rely on a set of function `push`, `pull` and `create` respectivaly copy data to the device, from the device, and allocate a memory space on the device.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e32a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "np_arr = np.random.rand(5,2)\n",
    "gpu_arr = cle.push(np_arr)\n",
    "out_arr = cle.pull(gpu_arr)\n",
    "\n",
    "print(f\"np_arr:  shape={np_arr.shape}, dtype={np_arr.dtype}, device={np_arr.device}, type={type(np_arr)}\")\n",
    "print(np_arr)\n",
    "print(f\"gpu_arr: shape={gpu_arr.shape}, dtype={gpu_arr.dtype}, device={gpu_arr.device.name}, type={type(gpu_arr)}\")\n",
    "print(gpu_arr)\n",
    "print(f\"out_arr: shape={out_arr.shape}, dtype={out_arr.dtype}, device={out_arr.device}, type={type(out_arr)}\")\n",
    "print(out_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89315076",
   "metadata": {},
   "source": [
    "### Exercice 1: Load an image into your device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f98fd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imread(\"https://imagej.net/ij/images/3_channel_inverted_luts.tif\")\n",
    "# TODO - check the image shape and push it to the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd13eb27",
   "metadata": {},
   "source": [
    "### Exercise 2: What is the largest array you can push to your device?\n",
    "\n",
    "One of the biggest limitation in GPU-acceleration is the memory limitation of your device, what is the size data you can push to your device? Does it fit your hardware specification?  \n",
    "Here, we want to see your hardware limitation and the type of error you would get if this happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92106951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - generate a large numpy array and push it to the GPU until ... it crashes ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a806bda",
   "metadata": {},
   "source": [
    "You can trace your device usage with various OSs application to see memory occupancy and the core usage:\n",
    "- MacOS: Activity Monitor > View > GPU History\n",
    "- Windows: Task Manager > Performance\n",
    "- NVIDIA: run `watch -n0.1 nvidia-smi` in a prompt / terminal\n",
    "- ...\n",
    "\n",
    "Now that you manage to fill up your device memory, delete the variable using `del`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c2c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - delete the GPU variable array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skbe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
