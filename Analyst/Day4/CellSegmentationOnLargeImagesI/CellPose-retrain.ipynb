{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24ca4453-2d4b-49e8-bc47-ffa601db7598",
   "metadata": {},
   "source": [
    "***\n",
    "# Retraining: transfert learning\n",
    "\n",
    "Part to retrain CellPose, copy-pasted from a previous course: https://github.com/gletort/NeubiasPasteur2023_AdvancedCellPose/blob/main/CellPose.ipynb\n",
    "\n",
    "When small training dataset is available, *pretraining* (on somewhat similar images and a close task) help to initialize the network.\n",
    "Fine-tuned a network in a new dataset close to the main dataset by *retraining* a network.\n",
    "\n",
    "Should all the layers be retrained ?\n",
    "\n",
    "For classification networks (https://www.sciencedirect.com/science/article/abs/pii/S0010482520304467): \n",
    "\n",
    "- Lot of images: retrain all\n",
    "- Few images, close to the training ones: high risk of overfitting. Instead retrain only on the last layer: use the features learned by the original training, and change only the last layer.\n",
    "- Few images, different: intermediate (not all the layers). Idea is that very first layers of cnn are very general (to images and network task). Risk of overfitting if retrain too many layers.\n",
    "\n",
    "\n",
    "- From scratch and few images: you can pretrain on a different task on the same images: e.g. training for segmentation: pretrain an auto-encoder (reconstruct the image), and then retrain on the segmentation.\n",
    "\n",
    "\n",
    "But with CellPose models, deeper layers are connected to shallow layers. This paper: https://arxiv.org/abs/2110.02196 suggests that freezing only the \"bottleneck block\" (the base of the U) gives better retraining. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d12e327-34c7-4ce0-91e7-c188b7c3a9c3",
   "metadata": {},
   "source": [
    "## Test of retraining CellPose model on our test dataset\n",
    "\n",
    "Test with oocytes segmentation: test without retraining, retraining from scratch, retraining from a pretrained network, pretrained+freezing some layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841b4ecb-b8df-4c14-8d64-d9643ac482a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import os, shutil, random, time\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import tempfile\n",
    "import napari\n",
    "\n",
    "## The \"classic\" CellPose version (version 3)\n",
    "import sys\n",
    "sys.path.insert(1,os.path.abspath('src/cellpose3/'))\n",
    "import src.cellpose3.cellpose as cellpose3\n",
    "import src.cellpose3.cellpose.models as cp3_models\n",
    "import src.cellpose3.cellpose.dynamics as cp3_dyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439fa198-6803-4c74-aa63-1db8858cbe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the data for retraining\n",
    "\n",
    "ootrainimg_files = glob(datadir+\"/dataOocytes/clin2/input/*.png\")\n",
    "ootrainmask_files = [ datadir+\"/dataOocytes/clin2/mask/\"+os.path.basename(filepath) for filepath in ootrainimg_files]\n",
    "ootrain_img = [cv2.imread(fimg, cv2.IMREAD_GRAYSCALE) for fimg in ootrainimg_files]\n",
    "ootrain_mask = [np.uint8(io.imread(fimg)/255) for fimg in ootrainmask_files]\n",
    "\n",
    "ootestimg_files = glob(datadir+\"/dataOocytes/clin2_test/input/*.png\")\n",
    "ootestmask_files = [ datadir+\"/dataOocytes/clin2_test/mask/\"+os.path.basename(filepath) for filepath in ootestimg_files]\n",
    "ootest_img = [cv2.imread(fimg, cv2.IMREAD_GRAYSCALE) for fimg in ootestimg_files]\n",
    "ootest_mask = [np.uint8(io.imread(fimg)/255) for fimg in ootestmask_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce27c04f-9a1d-4052-a590-d7fc048da27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cp3_models.CellposeModel(gpu=use_GPU, model_type='CP', nchan=2, pretrained_model=os.fspath(models.MODEL_DIR.joinpath(\"CP\")) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1253a41e-47b9-47fd-8cd4-a2bd3e11c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show the CellPose model architecture (Pytorch)\n",
    "print(model.net)\n",
    "\n",
    "## If you want to freeze some layers of the network, uncomment these lines and choose which layers to freeze\n",
    "\n",
    "#for param in model.net.downsample.parameters():\n",
    "#    param.requires_grad = False\n",
    "#for param in model.net.downsample.maxpool.parameters():\n",
    "#    param.requires_grad = False   \n",
    "#for param in model.net.downsample.down.res_down_3.proj.parameters():\n",
    "#    param.requires_grad = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ab7d8a-a735-485f-a93c-527c82c50acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_path = model.train(ootrain_img, ootrain_mask,\n",
    "                              min_train_masks = 1,\n",
    "                              test_data=ootest_img,\n",
    "                              test_labels=ootest_mask,\n",
    "                              channels=[0,0], \n",
    "                              save_path='./retrain', \n",
    "                              n_epochs=20,\n",
    "                              learning_rate=0.001, \n",
    "                              weight_decay=0.0001, \n",
    "                              model_name='test')\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "mem_usage = memory_usage(run_retrain)\n",
    "print('Maximum memory usage: %s' % max(mem_usage))\n",
    "end_time = time.time()\n",
    "print('Execution time:', end_time-start_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b813aaec-2b02-47c2-9360-9b1680dffb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test performance of retrained model\n",
    "masks, flows, styles  = model.eval(ootest_img, channels=[0,0])\n",
    "ap = metrics.average_precision(ootest_mask, masks)[0]\n",
    "print(f'>>> average precision at iou threshold 0.5 = {ap[:,0].mean():.3f}')\n",
    "print(f'>>> average precision at iou threshold 0.9 = {ap[:,2].mean():.3f}')\n",
    "\n",
    "cpmasks, flows, styles  = model.eval(test_imgs, channels=[0,0])\n",
    "ap = metrics.average_precision(test_masks, cpmasks)[0]\n",
    "print(f'>>> average precision at iou threshold 0.5 = {ap[:,0].mean():.3f}')\n",
    "print(f'>>> average precision at iou threshold 0.9 = {ap[:,2].mean():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686013ba-717f-4633-a521-b4db57d3bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look at results\n",
    "nimg = len(ootest_img)\n",
    "plt.figure(figsize=(nimg,2), dpi=200)\n",
    "for ind, img in enumerate(ootest_img):\n",
    "    plt.subplot(2,nimg,2*ind+1)\n",
    "    plt.imshow(img[0])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(2,nimg,2*ind+2)\n",
    "    mask = masks[ind]\n",
    "    plt.imshow(mask)\n",
    "    plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
